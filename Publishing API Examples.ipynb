{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains examples of various basic tasks using the [Socrata Publishing API](https://dev.socrata.com/publishers/getting-started.html). The principles we'll discuss apply across many languages, and there are [libraries available for most of the popular ones](https://dev.socrata.com/libraries/). For these examples, we'll be using xmunoz's community-built [sodapy](https://github.com/xmunoz/sodapy) library for Python 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Socrata's API relies on a standard username/password combination, with an optional (but highly-recommended) app token. How you choose to store these credentials is up to you; you simply need to provide them, usually just once per session. For this example, we're using [environment variables](https://en.wikipedia.org/wiki/Environment_variable), meaning that the operating system is storing them in memory and we just need to ask for them.\n",
    "\n",
    "Creating environment variables varies a lot by platform; it's different for [Windows](https://kb.wisc.edu/cae/page.php?id=24500), [Mac OS X](http://osxdaily.com/2015/07/28/set-enviornment-variables-mac-os-x/) and [Linux](https://www.digitalocean.com/community/tutorials/how-to-read-and-set-environmental-and-shell-variables-on-a-linux-vps). For now, let's assume that we have three such environment variables available to us:\n",
    "\n",
    "`SODA_USERNAME`; `SODA_PASSWORD`; `SODA_APP_TOKEN`\n",
    "\n",
    "Here's how we access them in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abraham.epton@socrata.com'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getenv('SODA_USERNAME', 'username goes here')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't display the others here, but let's assume they also exist. Using `sodapy` (which has [great documentation](https://github.com/xmunoz/sodapy)), let's create a client that lets us perform operations on a specific instance of the Socrata platform. In this case, it's a testing domain we use for education and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sodapy.Socrata object at 0x10f528cf8>\n"
     ]
    }
   ],
   "source": [
    "from sodapy import Socrata\n",
    "\n",
    "# Extract our credentials from the environment\n",
    "username = os.getenv('SODA_USERNAME', 'username goes here')\n",
    "password = os.getenv('SODA_PASSWORD', 'password goes here')\n",
    "app_token = os.getenv('SODA_APP_TOKEN', 'app token goes here')\n",
    "\n",
    "# Specify which Socrata domain we'd like to talk to\n",
    "domain = 'edu.demo.socrata.com'\n",
    "\n",
    "client = Socrata(domain, app_token, username=username, password=password)\n",
    "\n",
    "# What do we have here?\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we've got a client object that we can use to upload, download and modify datasets on the platform at [edu.demo.socrata.com](edu.demo.socrata.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create a dataset, you really only need to give Socrata the name you'd like to use. Often, we find it helpful to create some columns as well. To do so, pass in a list of the columns, along with their name and type, as below.\n",
    "\n",
    "We're also telling the platform which column to use as a *row identifier* - this lets the platform know which row we're talking about. Row identifiers should be unique in a particular dataset, though beyond that constraint they can be basically anything you like. Names aren't good row identifiers, usually, because they're rarely truly unique, but in this example our woodchucks can be guaranteed to have unique names, so we'll use that. (You don't need to specify a row identifier, unless you plan on using the *upsert* method we discuss in a little bit.)\n",
    "\n",
    "Note that when we specify which column is the row identifier, we use a slightly different version of the column name - `woodchuck_name` instead of `\"Woodchuck name\"`. This is because the API typically translates the human-readable display names into something easier for a machine to handle, so it makes everything lowercase and translates spaces to \\_s (among other things).\n",
    "\n",
    "This is just scratching the surface of what you can do when creating a dataset; the full set of options is described in more detail [in our documentation](https://dev.socrata.com/publishers/getting-started.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the columns you'd like this dataset to have\n",
    "columns = [\n",
    "  {\n",
    "    'name': 'Woodchuck name',\n",
    "    'dataTypeName': 'text'\n",
    "  },\n",
    "  {\n",
    "    'name': 'Amount of wood chucked',\n",
    "    'dataTypeName': 'number'\n",
    "  }\n",
    "]\n",
    "\n",
    "# Now actually create the dataset\n",
    "result = client.create('Wood chucked by various woodchucks', columns=columns, row_identifier='woodchuck_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the dataset is created, the response from the API will include the id (sometimes referred to as a four-by-four, since it's always 4 alphanumeric characters, then a hyphen, then another 4 alphanumeric characters). You'll need this id for all future operations using this dataset. Let's see what we get back from the API when we successfully create a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '6rpc-z7vc', 'name': 'Wood chucked by various woodchucks', 'averageRating': 0, 'createdAt': 1515020840, 'downloadCount': 0, 'hideFromCatalog': False, 'hideFromDataJson': False, 'newBackend': False, 'numberOfComments': 0, 'oid': 27646203, 'provenance': 'official', 'publicationAppendEnabled': False, 'publicationGroup': 14761964, 'publicationStage': 'unpublished', 'rowIdentifierColumnId': 338297198, 'rowsUpdatedAt': 1515020840, 'rowsUpdatedBy': '5sfv-yvt6', 'tableId': 14761964, 'totalTimesRated': 0, 'viewCount': 0, 'viewLastModified': 1515020840, 'viewType': 'tabular', 'columns': [{'id': 338297198, 'name': 'Woodchuck name', 'dataTypeName': 'text', 'fieldName': 'woodchuck_name', 'position': 1, 'renderTypeName': 'text', 'tableColumnId': 59270136, 'format': {}}, {'id': 338297199, 'name': 'Amount of wood chucked', 'dataTypeName': 'number', 'fieldName': 'amount_of_wood_chucked', 'position': 2, 'renderTypeName': 'number', 'tableColumnId': 59270137, 'format': {}}], 'metadata': {'rowIdentifier': 338297198}, 'owner': {'id': '5sfv-yvt6', 'displayName': 'Abraham Epton', 'screenName': 'Abraham Epton'}, 'query': {}, 'rights': ['read', 'write', 'add', 'delete', 'grant', 'add_column', 'remove_column', 'update_column', 'update_view', 'delete_view'], 'tableAuthor': {'id': '5sfv-yvt6', 'displayName': 'Abraham Epton', 'screenName': 'Abraham Epton'}, 'flags': ['default']}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we really care about is the dataset id, so let's save that for future use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_id = result.get('id', 'no dataset id found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we first create a dataset, it's in *working copy* mode, meaning it's not yet public. To make it public, just publish it like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "publication_result = client.publish(dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got a dataset, let's add some data to it. There are two strategies we can use for this: *replace* and *upsert*.\n",
    "\n",
    "When we replace a dataset, we do just what the name suggests: delete all the data that's currently there, and replace it with whatever we send along.\n",
    "\n",
    "When we upsert something on a dataset, we only change specific rows and leave the rest alone (this is quite useful for large datasets; imagine having to change a typo in one row of a million-row dataset). If the row we're upserting doesn't exist yet, we add it. (Hence the name: update + insert = upsert)\n",
    "\n",
    "Let's start by adding some data to the currently-empty dataset of wood chucked by woodchucks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'By RowIdentifier': 2,\n",
       " 'By SID': 0,\n",
       " 'Errors': 0,\n",
       " 'Rows Created': 2,\n",
       " 'Rows Deleted': 0,\n",
       " 'Rows Updated': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the replacement data - a list of objects, each one describing a row to be added\n",
    "data = [\n",
    "  {\n",
    "    'Woodchuck name': 'Tommy',\n",
    "    'Amount of wood chucked': 30\n",
    "  },\n",
    "  {\n",
    "    'Woodchuck name': 'Natalie',\n",
    "    'Amount of wood chucked': 12\n",
    "  }\n",
    "]\n",
    "\n",
    "# Just pass the list of replacement rows and the dataset id to the API, and let it do the rest\n",
    "client.replace(dataset_id, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey, look at that - we got some statistics back! The platform tells us how many rows we changed, and by which method.\n",
    "\n",
    "Now let's take a look at upserting. It works almost exactly the same as replacing a dataset does, but under the hood, the platform looks for row identifiers and only changes rows that already exist, inserting the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'By RowIdentifier': 2,\n",
       " 'By SID': 0,\n",
       " 'Errors': 0,\n",
       " 'Rows Created': 1,\n",
       " 'Rows Deleted': 0,\n",
       " 'Rows Updated': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the upsertable data - a list of objects, each one describing a row to be added. Make sure to pay attention\n",
    "# to the row identifier!\n",
    "data = [\n",
    "  {\n",
    "    'Woodchuck name': 'Natalie',\n",
    "    'Amount of wood chucked': 250\n",
    "  },\n",
    "  {\n",
    "    'Woodchuck name': 'Hercules',\n",
    "    'Amount of wood chucked': 3\n",
    "  }\n",
    "]\n",
    "\n",
    "# Just pass the list of replacement rows and the dataset id to the API, and let it do the rest\n",
    "# Note that we're explicitly calling upsert() and not replace()\n",
    "client.upsert(dataset_id, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the statistics, we modified 2 rows by row identifier: 1 row was updated and 1 was created, since the row identifier wasn't already present in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting a row or dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ashes to ashes, dust to dust: no example walkthrough would be complete without acknowleding the cycle of data, from birth to death. We have created datasets and rows, and now we must destroy them.\n",
    "\n",
    "First, let's delete a specific row. Again, we use the row identifier, and poor Hercules the Woodchuck's wood-chucking efforts will no longer be available for the world to examine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.delete(dataset_id, row_id='Hercules')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then, of course, we can delete the entire dataset, should we desire:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.delete(dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we got an HTTP code 200, our request was successful, and the dataset has been deleted. Thanks for reading!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
